This is a random collection of 200 words designed to see if nltk can properly detect proper tokens. I should try typing more complex words like U.S.A. , M.sc, and fan-dom. Maybe nltk can properly do it. I've typed maybe 50 words so far. I wonder if it matters whether I put spaces for my dots and commas.Like this sentence . I also want to test commas,so I will do that in this sentence. I also want to test if it can detect tokens through other special characters like ';'. I like oranges;I hate rap music ; Is this the real life? ; Maybe I should type the rest of words as complicated as I can. Hmm.... Lets see how I can do that. I can try detecting dashes as well. Rocket-man is not the right way to type that particular word. M*A*S*H* is a hard word to tokenize wonder how nltk does. Writing programming/scripting languages is probably a good idea: C# , C/C++ , HTML5 ,Python. Tokenizing seems to be the first step to text analytics. Proper tokens seems like the key for analysing text. Tokens' properties must be perfect for error-free operation. Stuck in a landslide no escape from reality!